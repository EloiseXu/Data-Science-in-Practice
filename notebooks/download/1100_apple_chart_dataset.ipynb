{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping apple charts using requests & Beautifulsoup\n",
    "\n",
    "Purpose\n",
    "In this notebook apple charts dataset will be scraped directly from itunes' website. Only title, description, rating, genre and the title of chart will be kept. We use Beautifulsoup instead of xpath to avoid any trouble brought by different positions of the same data in different apps' website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "import time\n",
    "import random\n",
    "\n",
    "import requests\n",
    "from requests.compat import urljoin\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_save_path = '../../datasets/1100_apple_chart_dataset.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each chart's url and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_start_url = ['https://www.apple.com/itunes/charts/top-grossing-apps/',\n",
    "           'https://www.apple.com/itunes/charts/free-apps/',\n",
    "           'https://www.apple.com/itunes/charts/paid-apps/']\n",
    "\n",
    "table_title = ['top-grossing-apps',\n",
    "             'free-apps',\n",
    "             'paid-apps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid being blocked, we change the 'User-Agent' every time we send a request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = { \"Accept\":\"text/html,application/xhtml+xml,application/xml;\",\n",
    "            \"Accept-Encoding\":\"gzip\",\n",
    "            \"Referer\":\"http://www.example.com/\" }\n",
    "\n",
    "user_agent_list = [\n",
    " 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "  'Chrome/45.0.2454.85 Safari/537.36 115Browser/6.0.3',\n",
    " 'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50',\n",
    " 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50',\n",
    " 'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)',\n",
    " 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)',\n",
    " 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1',\n",
    " 'Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_0) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11',\n",
    " 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SE 2.X MetaSr 1.0; SE 2.X MetaSr 1.0; .NET CLR 2.0.50727; SE 2.X MetaSr 1.0)',\n",
    " 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0',\n",
    " 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1',\n",
    "]\n",
    "\n",
    "def get_soup(search_url):\n",
    "    user_agent = random.choice(user_agent_list)\n",
    "    headers['User-Agent'] = user_agent\n",
    "    \n",
    "    wait_sec = random.random()*2\n",
    "    time.sleep(wait_sec)\n",
    "    searchHtml = requests.get(search_url, headers = headers)\n",
    "    soup = BeautifulSoup(searchHtml.text, features='html5lib')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_dataset = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Spider class. Url and title of a chart should be the input in initialization. The output of \"work\" should be a list containing items with title, description, rating, genre and the title of chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spider(object):\n",
    "    def __init__(self, search_url, chart_title):\n",
    "        self.soup = get_soup(search_url)\n",
    "        self.li = self.soup.find('div', {'id': 'main'}).find('section').find('div').find('ul').find_all('li')\n",
    "        self.link = []\n",
    "        self.title = []\n",
    "        self.chart = chart_title\n",
    "        \n",
    "        for x in self.li:\n",
    "            self.link.append(x.find('h3').find('a')['href'])\n",
    "            self.title.append(x.find('h3').find('a').string.strip())\n",
    "            \n",
    "    def work(self):\n",
    "        num = 0\n",
    "        result = []\n",
    "        for url in self.link:\n",
    "            soup = get_soup(url)\n",
    "            try:\n",
    "                rating = soup.find('li', {'class': 'product-header__list__item app-header__list__item--user-rating'}).find('figcaption').string.split(',')[0]\n",
    "            except:\n",
    "                rating = None\n",
    "            div = soup.find('div', {'class': 'animation-wrapper is-visible ember-view'})\n",
    "            try:\n",
    "                section = div.find_all('div', {'class': 'ember-view'})[1].find('section', {'class': 'l-content-width section section--hero product-hero ember-view'})\n",
    "                description = section.find('header').find_all('h2')[0].string\n",
    "            except:\n",
    "                description = None\n",
    "            try:\n",
    "                section = div.find_all('div', {'class': 'ember-view'})[1].find_all('section', {'class': 'l-content-width section section--bordered'})[3]\n",
    "                genre = section.find_all('dd')[2].find('a').string\n",
    "            except:\n",
    "                genre = None\n",
    "            \n",
    "            title = self.title[num]\n",
    "            num += 1\n",
    "            \n",
    "            item = {}\n",
    "            item['title'] = title\n",
    "            item['description'] = description\n",
    "            item['chart'] =self.chart\n",
    "            item['rating'] = rating\n",
    "            item['genre'] = genre\n",
    "             \n",
    "            result.append(item)\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any time failure of connection can happen. Thus we save the dataset in the format of json when we finish a chart, so that we can continue to work on the next chart after a failure of connection happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for url in apple_start_url:\n",
    "    spider = Spider(url, table_title[num])\n",
    "    num += 1\n",
    "    \n",
    "    apple_dataset.extend(spider.work())\n",
    "    with open(apple_save_path, 'w') as file:\n",
    "        file.write(json.dumps(apple_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
